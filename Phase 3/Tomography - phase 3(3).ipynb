{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import random\n",
    "import scipy as sp\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.svm  import SVR\n",
    "from scipy.stats import expon\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, make_scorer,r2_score\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tensorflow import keras \n",
    "import kerastuner as kt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as ks\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate our model, we use R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(X_test, Y_test, Y_pred):\n",
    "    u = np.sum((Y_test - Y_pred)**2)\n",
    "    v = np.sum((Y_test - np.mean(Y_test, axis=0))**2)\n",
    "\n",
    "    return 1 - u/v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We upload data here and process it. Then we split train and test data and print some of them to check if everything works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
      "0       0.360210  0.185256  0.460048  0.080421  0.253336 -0.007983  0.152587   \n",
      "1       0.183160  0.049485  0.134026  0.412545  0.364338  0.155872  0.294169   \n",
      "2       0.317019  0.374407  0.210512  0.515394  0.156974  0.203059  0.127567   \n",
      "3       0.275401  0.391152  0.116177  0.342888  0.206863  0.337896  0.274198   \n",
      "4       0.404453  0.563349  0.220006  0.456629  0.341826  0.115529 -0.018777   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "199996  0.289187  0.340885  0.377682  0.314358  0.276559  0.163274  0.362909   \n",
      "199997  0.281361  0.160791  0.455558  0.434837  0.085047  0.371651  0.160672   \n",
      "199998  0.038134  0.253515  0.242320  0.244411  0.093843  0.017178  0.079723   \n",
      "199999  0.224696  0.176235  0.105115  0.178771  0.194244  0.290372  0.384730   \n",
      "200000  0.221576  0.386561  0.175625  0.343328  0.156447  0.251569  0.152887   \n",
      "\n",
      "        feature8  feature9  feature10  ...    label7    label8    label9  \\\n",
      "0       0.227537  0.166972   0.265079  ...  0.118635  0.196883  0.246268   \n",
      "1       0.168458  0.303741   0.342982  ...  0.274267  0.280900  0.415232   \n",
      "2       0.230485  0.357478  -0.012267  ...  0.275270  0.194068  0.321588   \n",
      "3       0.293513  0.269403   0.315489  ...  0.299158  0.322152  0.271518   \n",
      "4       0.258622  0.249453   0.295579  ...  0.094808  0.169235  0.323117   \n",
      "...          ...       ...        ...  ...       ...       ...       ...   \n",
      "199996  0.103982  0.177582   0.425338  ...  0.318714  0.245920  0.122562   \n",
      "199997  0.247714  0.234462   0.485067  ...  0.178525  0.216407  0.289360   \n",
      "199998  0.088074  0.253995   0.496475  ...  0.093518  0.167857  0.261455   \n",
      "199999  0.259977  0.034164   0.089312  ...  0.374373  0.234412  0.246158   \n",
      "200000  0.085132  0.373567   0.356038  ...  0.144022  0.232217  0.187229   \n",
      "\n",
      "         label10   label11   label12   label13   label14   label15   label16  \n",
      "0       0.205265  0.278040  0.222535  0.174445  0.253447  0.129345  0.267256  \n",
      "1       0.212381  0.300226  0.270276  0.347799  0.179432  0.156617  0.208602  \n",
      "2       0.174975  0.288361  0.286966  0.231219  0.311063  0.216990  0.388601  \n",
      "3       0.216573  0.259646  0.288883  0.196624  0.209436  0.048146  0.274570  \n",
      "4       0.332209  0.228379  0.409234  0.108657  0.337846  0.084251  0.249564  \n",
      "...          ...       ...       ...       ...       ...       ...       ...  \n",
      "199996  0.194412  0.246453  0.197157  0.143363  0.189286  0.047025  0.234004  \n",
      "199997  0.331677  0.493102  0.378247  0.081407  0.254731  0.184891  0.122690  \n",
      "199998  0.445459  0.319957  0.280815  0.262249  0.300760  0.212445  0.213376  \n",
      "199999  0.140372  0.259367  0.233497  0.203594  0.300366  0.274382  0.190160  \n",
      "200000  0.279625  0.127945  0.277768  0.186617  0.135811  0.029654  0.227179  \n",
      "\n",
      "[200001 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "noise_std = 0.1\n",
    "\n",
    "# df = pd.read_csv('Tomography - noise_' + str(noise_std) + ' - No of removed measurements_0.csv')\n",
    "df=pd.read_csv('lol.csv')\n",
    "\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# df = df.sample(n=10000)\n",
    "# df = df.sample(n=20000)\n",
    "\n",
    "print(df)\n",
    "\n",
    "# X = df[[\"feature2\", \"feature3\", \"feature4\", \"feature5\", \"feature6\", \"feature7\", \"feature8\", \"feature9\", \"feature10\", \"feature11\", \"feature12\", \"feature13\", \"feature14\", \"feature15\", \"feature16\"]].multiply(1/df['feature1'], axis=\"index\").to_numpy()\n",
    "\n",
    "X = df[[\"feature1\", \"feature2\", \"feature3\", \"feature4\", \"feature5\", \"feature6\", \"feature7\", \"feature8\", \"feature9\", \"feature10\", \"feature11\", \"feature12\", \"feature13\", \"feature14\", \"feature15\", \"feature16\"]].to_numpy()\n",
    "\n",
    "\n",
    "Y = df[[\"label1\", \"label2\", \"label3\", \"label4\", \"label5\", \"label6\", \"label7\", \"label8\", \"label9\", \"label10\", \"label11\", \"label12\", \"label13\", \"label14\", \"label15\", \"label16\"]].to_numpy()\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "\n",
    "free_params = 16\n",
    "\n",
    "# print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40001, 16) (40001, 16) (160000, 16) (160000, 16)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, Y_test.shape, X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train, axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we construct a neural network with a random structure to see how it works. We then plot losses in each epoch and see how the model has performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">680</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,230</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">496</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │           \u001b[38;5;34m680\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m1,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m1,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m1,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m1,230\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m496\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,326</span> (28.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,326\u001b[0m (28.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,326</span> (28.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,326\u001b[0m (28.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow import keras as ks\n",
    "\n",
    "model = ks.Sequential()\n",
    "model.add(ks.layers.Dense(40, activation=ks.activations.relu, input_dim = free_params)  )\n",
    "model.add(ks.layers.Dense(40, activation=ks.activations.relu) )#, kernel_regularizer=keras.regularizers.l2(.1))  )\n",
    "model.add(ks.layers.Dense(40, activation=ks.activations.relu) )\n",
    "model.add(ks.layers.Dense(40, activation=ks.activations.relu) )\n",
    "model.add(ks.layers.Dense(30, activation=ks.activations.relu)  )\n",
    "\n",
    "model.add(ks.layers.Dense(free_params)  )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.compile(optimizer= 'adam', \n",
    "              loss = 'mean_squared_error'\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.0202242 ,  0.00665927,  0.01166439,  0.05572757,  0.02327701,\n",
       "         0.01065541, -0.05963064, -0.02361289,  0.02244134,  0.01173764,\n",
       "        -0.04028575, -0.00664761,  0.04913182,  0.00822004, -0.08984851,\n",
       "        -0.0156356 ],\n",
       "       [ 0.00049104,  0.00066891,  0.01778368,  0.03448933,  0.0116536 ,\n",
       "         0.00366527, -0.03444787,  0.00410743,  0.0103042 ,  0.02654054,\n",
       "        -0.01504569, -0.01772494,  0.03655645, -0.01393889, -0.04616621,\n",
       "        -0.01190288],\n",
       "       [ 0.00153807, -0.00498673,  0.01693722,  0.06503484,  0.02685812,\n",
       "         0.00071051, -0.08814217, -0.02888308,  0.02992259,  0.0467741 ,\n",
       "        -0.0165442 , -0.01063502,  0.05983124, -0.00893957, -0.0727936 ,\n",
       "        -0.01321888]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0170 - val_loss: 0.0049\n",
      "Epoch 2/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 3/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 4/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 5/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 6/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 7/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 8/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 9/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 10/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 11/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 12/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 13/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 14/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 15/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 16/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 17/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 18/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 19/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 20/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 21/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 22/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 23/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 24/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 25/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 26/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 27/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 28/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 29/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 30/30\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 30\n",
    "btch_size = 200\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2)\n",
    "\n",
    "history = model.fit( x=X_train,\n",
    "          y=Y_train,\n",
    "          epochs=n_epoch,\n",
    "          batch_size = btch_size,\n",
    "          validation_data=(X_val, Y_val),\n",
    "          shuffle = True,\n",
    "        #   st\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "# Plot training & validation loss values\n",
    "ax = fig.add_subplot(1,1,1, title = 'Model loss', ylabel= 'Loss')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0042\n",
      "\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "test loss: 0.004241792019456625\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, Y_test)\n",
    "Y_pred = model.predict(X_test)\n",
    "print(\"test loss:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step\n",
      "Test Score: 0.6904374102360669  Train Score: 0.6912554441378447\n"
     ]
    }
   ],
   "source": [
    "score = r2_score(Y_test,Y_pred)#score_model(X_test, Y_test, model.predict(X_test))\n",
    "scoretr=r2_score(Y_train,model.predict(X_train))\n",
    "print('Test Score: ' + str( score  )   + '  Train Score: ' + str( scoretr ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores here are of the order of the best scores we saw in the traditional models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.008692579343914986,\n",
       "  0.004759572446346283,\n",
       "  0.004504113458096981,\n",
       "  0.004408717155456543,\n",
       "  0.004370871465653181,\n",
       "  0.004349996335804462,\n",
       "  0.004334215074777603,\n",
       "  0.004314221441745758,\n",
       "  0.004303262569010258,\n",
       "  0.00429002707824111,\n",
       "  0.004279803484678268,\n",
       "  0.004266796167939901,\n",
       "  0.004256467800587416,\n",
       "  0.004250263795256615,\n",
       "  0.004241734277456999,\n",
       "  0.004231607541441917,\n",
       "  0.004230536986142397,\n",
       "  0.004227645695209503,\n",
       "  0.004217630717903376,\n",
       "  0.004213432315737009,\n",
       "  0.0042099496349692345,\n",
       "  0.004209124017506838,\n",
       "  0.004202647600322962,\n",
       "  0.004198778420686722,\n",
       "  0.004194254986941814,\n",
       "  0.004196451511234045,\n",
       "  0.0041961814276874065,\n",
       "  0.004191794898360968,\n",
       "  0.004188879393041134,\n",
       "  0.0041867452673614025],\n",
       " 'val_loss': [0.00492068799212575,\n",
       "  0.004596219398081303,\n",
       "  0.004404160194098949,\n",
       "  0.004354722797870636,\n",
       "  0.004313749726861715,\n",
       "  0.004400963429361582,\n",
       "  0.004335761535912752,\n",
       "  0.004290038254112005,\n",
       "  0.004269675817340612,\n",
       "  0.00431130500510335,\n",
       "  0.004239289090037346,\n",
       "  0.004249592777341604,\n",
       "  0.004258571658283472,\n",
       "  0.0042683738283813,\n",
       "  0.004234932363033295,\n",
       "  0.004233250394463539,\n",
       "  0.004233121406286955,\n",
       "  0.00425292132422328,\n",
       "  0.004204786382615566,\n",
       "  0.004231360740959644,\n",
       "  0.004195772111415863,\n",
       "  0.004178260453045368,\n",
       "  0.004193812143057585,\n",
       "  0.004154522903263569,\n",
       "  0.004164503887295723,\n",
       "  0.0041556814685463905,\n",
       "  0.004205908626317978,\n",
       "  0.004200752824544907,\n",
       "  0.0041712564416229725,\n",
       "  0.004227906931191683]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we fix the neuron numbers and tune the number of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Flatten(input_shape=(16,)))\n",
    "\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=30, max_value=50, step=4)\n",
    "  model.add(keras.layers.Dense(units=hp_units,\n",
    "                               activation='relu'))\n",
    "                              #  kernel_regularizer=keras.regularizers.l2(.05)))\n",
    "  hp_units2 = hp.Int('units2', min_value=30, max_value=50, step=4)\n",
    "  model.add(keras.layers.Dense(units=hp_units2,\n",
    "                               activation='relu'))\n",
    "  hp_units3 = hp.Int('units3', min_value=30, max_value=50, step=4)\n",
    "  model.add(keras.layers.Dense(units=hp_units3,\n",
    "                               activation='relu'))\n",
    "                              #  kernel_regularizer=keras.regularizers.l2(.05)))\n",
    "  hp_units4 = hp.Int('units4', min_value=30, max_value=50, step=4)\n",
    "  model.add(keras.layers.Dense(units=hp_units4,\n",
    "                               activation='relu'))\n",
    "  hp_units5 = hp.Int('units5', min_value=8, max_value=32, step=4)\n",
    "  model.add(keras.layers.Dense(units=hp_units5,\n",
    "                               activation='relu'))\n",
    "  hp_units6 = hp.Int('units6', min_value=8, max_value=32, step=4)\n",
    "  model.add(keras.layers.Dense(units=hp_units6,\n",
    "                               activation='relu'))\n",
    "\n",
    "  model.add(keras.layers.Dense(16))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  learning_rate = 0.001\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                loss='mean_squared_error')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 25s]\n",
      "val_loss: 0.004333809949457645\n",
      "\n",
      "Best val_loss So Far: 0.004293193109333515\n",
      "Total elapsed time: 00h 05m 50s\n",
      "\n",
      "The hyperparameter search is complete. The optimal numbers: {'units': 34, 'units2': 50, 'units3': 38, 'units4': 38, 'units5': 32, 'units6': 32, 'tuner/epochs': 10, 'tuner/initial_epoch': 4, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': '0013'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dirbigdata',\n",
    "                     project_name='intro_to_kt',overwrite=True)\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(X_train, Y_train,\n",
    "             epochs=4,\n",
    "             batch_size = 100,\n",
    "             validation_split=0.2,\n",
    "             callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal numbers: {best_hps.values}\n",
    "\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.0138 - val_loss: 0.0047\n",
      "Epoch 2/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 3/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 4/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 5/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 6/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 7/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 8/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 9/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 10/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 11/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 12/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 13/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 14/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 15/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Best epoch: 15\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    epochs=15,\n",
    "                    batch_size = 100,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "\n",
    "val_loss_per_epoch = history.history['val_loss']\n",
    "best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0042\n",
      "\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "test loss: 0.004165728576481342\n",
      "\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step\n",
      "Test Score: 0.6960736086974488  Train Score: 0.6966171930032389\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, Y_test)\n",
    "Y_pred = model.predict(X_test)\n",
    "print(\"test loss:\", results)\n",
    "score = score_model(X_test, Y_test, model.predict(X_test))\n",
    "\n",
    "print('Test Score: ' + str( score_model(X_test, Y_test, Y_pred  ))   + '  Train Score: ' + str( score_model(X_train, Y_train, model.predict(X_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6960051853998573"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores are rather similar to that of the previous model's. Next we tune layers and neurons simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    \"\"\"\n",
    "    Builds model and sets up hyperparameter space to search.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    hp : HyperParameter object\n",
    "        Configures hyperparameters to tune.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    model : keras model\n",
    "        Compiled model with hyperparameters to tune.\n",
    "    \"\"\"\n",
    "    # Initialize sequential API and start building model.\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(16,)))\n",
    "    \n",
    "    # Tune the number of hidden layers and units in each.\n",
    "    # Number of hidden layers: 1 - 5\n",
    "    # Number of Units: 32 - 512 with stepsize of 32\n",
    "    for i in range(1, hp.Int(\"num_layers\", 4, 8)):\n",
    "        model.add(\n",
    "            keras.layers.Dense(\n",
    "                units=hp.Int(\"units_\" + str(i), min_value=8, max_value=40, step=4),\n",
    "                activation=\"relu\")\n",
    "            )\n",
    "        \n",
    "        # Tune dropout layer with values from 0 - 0.3 with stepsize of 0.1.\n",
    "\n",
    "    \n",
    "    # Add output layer.\n",
    "    model.add(keras.layers.Dense(units=16))\n",
    "    \n",
    "    # Tune learning rate for Adam optimizer with values from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = 0.001 #hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    # Define optimizer, loss, and metrics\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss='mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 27s]\n",
      "val_loss: 0.005516663193702698\n",
      "\n",
      "Best val_loss So Far: 0.004280653782188892\n",
      "Total elapsed time: 00h 05m 54s\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is {'num_layers': 5, 'units_1': 40, 'units_2': 40, 'units_3': 28, 'units_4': 32, 'units_5': 36, 'units_6': 36, 'units_7': 40, 'tuner/epochs': 10, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=10,\n",
    "                     directory='my_dirlaybigerdata',\n",
    "                     project_name='intro_to_ktlay',overwrite=True)\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(X_train, Y_train,\n",
    "             epochs=12,\n",
    "             batch_size = 100,\n",
    "             validation_split=0.2,\n",
    "             callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.values}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.0120 - val_loss: 0.0045\n",
      "Epoch 2/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 3/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 4/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 5/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 6/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 7/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 8/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 9/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 10/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 11/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 12/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 13/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 14/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 15/15\n",
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Best epoch: 11\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    epochs=15,\n",
    "                    batch_size = 100,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "\n",
    "val_loss_per_epoch = history.history['val_loss']\n",
    "best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "[[0.29698839 0.26153632 0.16092356 0.29558059 0.30142523 0.14005006\n",
      "  0.25420936 0.09327975 0.16745461 0.26664446 0.07301361 0.11507371\n",
      "  0.24771244 0.17817582 0.2879527  0.17029132]] [[0.27674845 0.30883107 0.23624748 0.44214255 0.26309243 0.15676169\n",
      "  0.18598092 0.14735922 0.18743393 0.20877847 0.10028026 0.25234348\n",
      "  0.21046302 0.20999262 0.25689518 0.18145663]]\n",
      "\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step\n",
      "Test Score: 0.6916913997387658  Train Score: 0.6921797617554826\n"
     ]
    }
   ],
   "source": [
    "print(Y_test[[200]],model.predict(X_test[[200]]))\n",
    "Y_pred=model.predict(X_test)\n",
    "scorete = r2_score(Y_test,Y_pred)\n",
    "mtx=model.predict(X_train)\n",
    "scoretr=r2_score(Y_train,model.predict(X_train))\n",
    "print('Test Score: ' + str( scorete)    + '  Train Score: ' + str( scoretr ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, scores are rather the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">680</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,148</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │           \u001b[38;5;34m680\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m1,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │         \u001b[38;5;34m1,148\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,774</span> (57.71 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,774\u001b[0m (57.71 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,924</span> (19.23 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,924\u001b[0m (19.23 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,850</span> (38.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m9,850\u001b[0m (38.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we see how the model works for different sizes of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kavyan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0580 - val_loss: 0.0172\n",
      "Epoch 2/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0150 - val_loss: 0.0115\n",
      "Epoch 3/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0112 - val_loss: 0.0103\n",
      "Epoch 4/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0101 - val_loss: 0.0093\n",
      "Epoch 5/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0091 - val_loss: 0.0084\n",
      "Epoch 6/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0082 - val_loss: 0.0075\n",
      "Epoch 7/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0075 - val_loss: 0.0068\n",
      "Epoch 8/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 9/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 10/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 11/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 12/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 13/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 14/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 15/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 16/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 17/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 18/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 19/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 20/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 21/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 22/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 23/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 24/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 25/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 26/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 27/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 28/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 29/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 30/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kavyan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0478 - val_loss: 0.0111\n",
      "Epoch 2/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0095 - val_loss: 0.0074\n",
      "Epoch 3/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 4/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 5/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 6/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 7/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 8/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 9/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 10/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 11/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 12/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 13/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 14/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 15/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 16/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 17/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 18/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 19/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 20/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 21/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 22/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 23/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 24/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 25/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 26/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 27/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 28/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 29/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 30/30\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kavyan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0277 - val_loss: 0.0086\n",
      "Epoch 2/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - val_loss: 0.0055\n",
      "Epoch 3/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 4/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 5/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 6/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 7/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 8/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 9/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 10/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 11/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 12/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 13/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 14/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 15/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 16/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 17/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 18/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 19/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 20/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 21/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 22/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 23/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 24/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 25/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 26/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 27/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 28/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 29/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 30/30\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kavyan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0239 - val_loss: 0.0064\n",
      "Epoch 2/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 3/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 4/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 5/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 6/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 7/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 8/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 9/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 10/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 11/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 12/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 13/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 14/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 15/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 16/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 17/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 18/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 19/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 20/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 21/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 22/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 23/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 24/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 25/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 26/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 27/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 28/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 29/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 30/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 957us/step\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kavyan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0234 - val_loss: 0.0060\n",
      "Epoch 2/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 3/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 4/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 5/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 6/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 7/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 8/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 9/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 10/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 11/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 12/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 13/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 14/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 15/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 16/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 17/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 18/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 19/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 20/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 21/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 22/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 23/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 24/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 25/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 26/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 27/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 28/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 29/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 30/30\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 941us/step\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kavyan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0257 - val_loss: 0.0054\n",
      "Epoch 2/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 3/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 4/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 5/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 6/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 7/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 8/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 9/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 10/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 11/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 12/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 13/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 14/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 15/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 16/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 17/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 18/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 19/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 20/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 21/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 22/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 23/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 24/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 25/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 26/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 27/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 28/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 29/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 30/30\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "\u001b[1m1800/1800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 981us/step\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kavyan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0212 - val_loss: 0.0065\n",
      "Epoch 2/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 3/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 4/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 5/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 6/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 7/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 8/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 9/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 10/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 11/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 12/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 13/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 14/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 15/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 16/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 17/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 18/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 19/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 20/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 21/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 22/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 23/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 24/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 25/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 26/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 27/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 28/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 29/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 30/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "noise_std = 0.1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df1=pd.read_csv('Tomography - noise_0.1 - No of removed measurements_0.csv')\n",
    "df1 = df1.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "data_sizes = [10000, 30000, 50000, 70000, 80000, 90000, len(df1) ]\n",
    "\n",
    "\n",
    "\n",
    "train_scores= []\n",
    "test_scores = []\n",
    "\n",
    "\n",
    "for data_size in data_sizes:\n",
    "    \n",
    "    df = df1.sample(n=data_size)\n",
    "    # df = df.sample(n=10000)\n",
    "    # df = df.sample(n=20000)\n",
    "\n",
    "    # print(df)\n",
    "\n",
    "    # X = df[[\"feature2\", \"feature3\", \"feature4\", \"feature5\", \"feature6\", \"feature7\", \"feature8\", \"feature9\", \"feature10\", \"feature11\", \"feature12\", \"feature13\", \"feature14\", \"feature15\", \"feature16\"]].multiply(1/df['feature1'], axis=\"index\").to_numpy()\n",
    "\n",
    "    X = df[[\"feature1\", \"feature2\", \"feature3\", \"feature4\", \"feature5\", \"feature6\", \"feature7\", \"feature8\", \"feature9\", \"feature10\", \"feature11\", \"feature12\", \"feature13\", \"feature14\", \"feature15\", \"feature16\"]].to_numpy()\n",
    "\n",
    "\n",
    "    Y = df[[\"label1\", \"label2\", \"label3\", \"label4\", \"label5\", \"label6\", \"label7\", \"label8\", \"label9\", \"label10\", \"label11\", \"label12\", \"label13\", \"label14\", \"label15\", \"label16\"]].to_numpy()\n",
    "\n",
    "    # X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "\n",
    "    free_params = 16\n",
    "\n",
    "\n",
    "\n",
    "    model = ks.Sequential()\n",
    "    model.add(ks.layers.Dense(40, activation=ks.activations.relu, input_dim = free_params)  )\n",
    "    model.add(ks.layers.Dense(40, activation=ks.activations.relu) )\n",
    "    model.add(ks.layers.Dense(40, activation=ks.activations.relu) )\n",
    "    model.add(ks.layers.Dense(40, activation=ks.activations.relu) )\n",
    "    model.add(ks.layers.Dense(30, activation=ks.activations.relu)  )\n",
    "\n",
    "    model.add(ks.layers.Dense(free_params)  )\n",
    "    # model.summary()\n",
    "\n",
    "\n",
    "    model.compile(optimizer= 'adam',\n",
    "              loss = 'mean_squared_error'\n",
    "              )\n",
    "    \n",
    "\n",
    "    n_epoch = 30\n",
    "    btch_size = 200\n",
    "\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2)\n",
    "\n",
    "    history = model.fit( x=X_train,\n",
    "            y=Y_train,\n",
    "            epochs=n_epoch,\n",
    "            batch_size = btch_size,\n",
    "            validation_data=(X_val, Y_val),\n",
    "            shuffle = True,\n",
    "            #   st\n",
    "            )\n",
    "    \n",
    "    train_scores.append(  r2_score(Y_train,model.predict(X_train)) )\n",
    "    test_scores.append(  r2_score(Y_test,model.predict(X_test)) )\n",
    "\n",
    "    # print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data_sizes, train_scores, label='Train Scores', color='b')\n",
    "plt.plot(data_sizes, test_scores, label='Test Scores', color='r', linestyle='--')\n",
    " \n",
    "# Adding labels and title\n",
    "plt.xlabel('Data Size')\n",
    "plt.ylabel('Score')\n",
    "# plt.title('Multiple Lines Plot')\n",
    " \n",
    "# Displaying the legend and the plot\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that more data will not help that much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
